{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from glob import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a0da97aacfa04a329147b9294e047c6e', 'b966edaecd2e40d4b36f3f1c72d48276']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_run_mappings['147575009518632148']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_registered_models():\n",
    "    register_model_details=[]\n",
    "    for model in client.search_registered_models():\n",
    "        name=model.name\n",
    "        run_id=model.latest_versions[0].run_id\n",
    "        # stage=model.latest_versions[0].current_stage\n",
    "        date_updated=str(datetime.datetime.fromtimestamp(model.latest_versions[0].last_updated_timestamp/1e3)).split(' ')[0]\n",
    "        register_model_details.append([name,date_updated,run_id])\n",
    "    return register_model_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Dummy1', '2024-01-22', 'a0da97aacfa04a329147b9294e047c6e']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_registered_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_past_experiments_details():\n",
    "    def __init__(self):\n",
    "        self.client=mlflow.MlflowClient()\n",
    "        self.generate_dates_to_exps_mappings()\n",
    "        self.generate_exps_to_runs_mappings()\n",
    "\n",
    "    def get_registered_models(self):\n",
    "        register_model_details=[]\n",
    "        for model in self.client.search_registered_models():\n",
    "            name=model.name\n",
    "            run_id=model.latest_versions[0].run_id\n",
    "            stage=model.latest_versions[0].current_stage\n",
    "            version=model.latest_versions[0].version\n",
    "            date_updated=str(datetime.datetime.fromtimestamp(model.latest_versions[0].last_updated_timestamp/1e3)).split(' ')[0]\n",
    "            register_model_details.append([name,version,stage,date_updated,run_id])\n",
    "        return register_model_details\n",
    "\n",
    "    def generate_dates_to_exps_mappings(self):\n",
    "        self.exp_ids=[[x.experiment_id,str(datetime.datetime.fromtimestamp(x.last_update_time/1e3)).split(' ')[0]] for x in self.client.search_experiments()][:-1] # removing the default exp\n",
    "        self.unique_dates=list(set([i[1] for i in self.exp_ids]))\n",
    "        self.dates_to_exps={d:[] for d in self.unique_dates}\n",
    "        for d in self.dates_to_exps:\n",
    "            for i in self.exp_ids:\n",
    "                if d in i:\n",
    "                    self.dates_to_exps[d].append(i[0])\n",
    "        self.experiment_ids=[ e for es in self.dates_to_exps.values() for e in es]\n",
    "\n",
    "    def generate_exps_to_runs_mappings(self):\n",
    "        self.exps_to_runs={y:[x.split('/')[-1] for x in glob(f\"mlruns/{y}/*\") if 'meta' not in x] for y in self.experiment_ids}\n",
    "    \n",
    "    def get_exp_and_run_losses_for_date_detailed(self,date:str):\n",
    "\n",
    "        exps=self.dates_to_exps[date]\n",
    "\n",
    "        losses_on_date={}\n",
    "        for exp in exps:\n",
    "            \n",
    "            losses_on_date[exp]={}\n",
    "            runs=self.exps_to_runs[exp]\n",
    "            for run in runs:\n",
    "                run_losses=self.get_run_losses_detailed(exp,run)\n",
    "                losses_on_date[exp][run]={}\n",
    "                losses_on_date[exp][run]=run_losses\n",
    "\n",
    "        return losses_on_date\n",
    "    \n",
    "    def get_exp_and_run_losses_for_date_table(self,date:str):\n",
    "\n",
    "        exps=self.dates_to_exps[date]\n",
    "\n",
    "        losses_on_date={}\n",
    "        for exp in exps:\n",
    "            \n",
    "            losses_on_date[exp]={}\n",
    "            runs=self.exps_to_runs[exp]\n",
    "            for run in runs:\n",
    "                run_losses=self.get_run_losses_table(exp,run)\n",
    "                losses_on_date[exp][run]={}\n",
    "                losses_on_date[exp][run]=run_losses\n",
    "\n",
    "        return losses_on_date\n",
    "\n",
    "    def get_run_losses_detailed(self,exp_id,run_id):\n",
    "        x=[]\n",
    "        with open(f'mlruns/{exp_id}/{run_id}/metrics/train_loss') as f:\n",
    "            x=f.read()\n",
    "            train_losses={y[2]:y[1] for y in [y.split(' ') for y in x.split('\\n')][:-1]}\n",
    "        with open(f'mlruns/{exp_id}/{run_id}/metrics/val_loss') as f:\n",
    "            x=f.read()\n",
    "            val_losses={y[2]:y[1] for y in [y.split(' ') for y in x.split('\\n')][:-1]}\n",
    "        epochs=list(train_losses.keys())\n",
    "        losses={}\n",
    "        for e in epochs:\n",
    "            losses[e]=[train_losses[e],val_losses[e]]\n",
    "        return losses\n",
    "    \n",
    "    def get_run_losses_table(self,exp_id,run_id):\n",
    "        x=[]\n",
    "        with open(f'mlruns/{exp_id}/{run_id}/artifacts/comparison_table.json','r') as f:\n",
    "            json_file=json.load(f)\n",
    "            return [json_file[\"data\"][0][2],json_file[\"data\"][0][3]]\n",
    "    \n",
    "    def compare_losses(self,date,runs):\n",
    "        losses_table=self.get_exp_and_run_losses_for_date_table(date)\n",
    "        run_losses=dict(x for row in losses_table.values() for x in row.items())\n",
    "        return {r:run_losses[r] for r in runs}\n",
    "\n",
    "    def get_run_ids(self,exps):\n",
    "\n",
    "        runs=[]\n",
    "        for e in exps:\n",
    "            runs.extend(self.exps_to_runs[e])\n",
    "        return runs\n",
    "    \n",
    "    def get_exp_names(self,exp_ids):\n",
    "\n",
    "        names=[]\n",
    "        for exp_id in exp_ids:\n",
    "            names.append(self.client.get_experiment(exp_id).name)\n",
    "        return names\n",
    "    \n",
    "    def experiment_names_to_ids(self, names):\n",
    "\n",
    "        exp_ids=[]\n",
    "        for name in names:\n",
    "            exp_ids.append(self.client.get_experiment_by_name(name).experiment_id)\n",
    "        return exp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2024-01-22': ['147575009518632148',\n",
       "  '432371529360376795',\n",
       "  '153729051477138785'],\n",
       " '2024-01-18': ['737505758160016794', '765617377597547522']}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=get_past_experiments_details()\n",
    "e.dates_to_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'147575009518632148': ['a0da97aacfa04a329147b9294e047c6e',\n",
       "  'b966edaecd2e40d4b36f3f1c72d48276'],\n",
       " '432371529360376795': ['1794fe922c7c45fd853f963d72ef48cf'],\n",
       " '153729051477138785': ['f8b2fec17ec247769493788b99d13bd7'],\n",
       " '737505758160016794': ['ec09f34cda7a4c26a0bfd3ac32b06d27',\n",
       "  'ac75b7a4aa7f4e309f12b2d784ff322d',\n",
       "  'a1d1fa7cc7a5492786015b51c59c86dd',\n",
       "  '861c51cb34c44d088fac890c29d5d605'],\n",
       " '765617377597547522': ['8b03eae6293a4e48b00d714500d3e489',\n",
       "  '973abe2fa3c945ceb8542bda25a8226f',\n",
       "  'dc85bb2d59f64f7eb480f743ca166e8e']}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.exps_to_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_table=e.get_exp_and_run_losses_for_date_table('2024-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=e.get_exp_and_run_losses_for_date_detailed('2024-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a0da97aacfa04a329147b9294e047c6e': [15357.1767578125, 9365.21484375],\n",
       " 'b966edaecd2e40d4b36f3f1c72d48276': [15258.109375, 9090.5361328125]}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.compare_losses('2024-01-22',['a0da97aacfa04a329147b9294e047c6e',\n",
    "  'b966edaecd2e40d4b36f3f1c72d48276'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['a0da97aacfa04a329147b9294e047c6e','b966edaecd2e40d4b36f3f1c72d48276']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-22 11:39:44.762000'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.datetime.fromtimestamp(client.get_run(runs[0]).info.end_time/1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1705903784762"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-22'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.datetime.fromtimestamp(model.latest_versions[0].last_updated_timestamp/1e3)).split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_updated_timestamp, name, run_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_k8s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
