{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from glob import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_run_mappings['147575009518632148']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_registered_models():\n",
    "    register_model_details=[]\n",
    "    for model in client.search_registered_models():\n",
    "        name=model.name\n",
    "        run_id=model.latest_versions[0].run_id\n",
    "        # stage=model.latest_versions[0].current_stage\n",
    "        date_updated=str(datetime.datetime.fromtimestamp(model.latest_versions[0].last_updated_timestamp/1e3)).split(' ')[0]\n",
    "        register_model_details.append([name,date_updated,run_id])\n",
    "    return register_model_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_registered_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_past_experiments_details():\n",
    "    def __init__(self):\n",
    "        self.client=mlflow.MlflowClient()\n",
    "        self.generate_dates_to_exps_mappings()\n",
    "        self.generate_exps_to_runs_mappings()\n",
    "\n",
    "    def get_registered_models(self):\n",
    "        register_model_details=[]\n",
    "        for model in self.client.search_registered_models():\n",
    "            name=model.name\n",
    "            run_id=model.latest_versions[0].run_id\n",
    "            stage=model.latest_versions[0].current_stage\n",
    "            version=model.latest_versions[0].version\n",
    "            date_updated=str(datetime.datetime.fromtimestamp(model.latest_versions[0].last_updated_timestamp/1e3)).split(' ')[0]\n",
    "            register_model_details.append([name,version,stage,date_updated,run_id])\n",
    "        return register_model_details\n",
    "\n",
    "    def generate_dates_to_exps_mappings(self):\n",
    "        self.exp_ids=[[x.experiment_id,str(datetime.datetime.fromtimestamp(x.last_update_time/1e3)).split(' ')[0]] for x in self.client.search_experiments()][:-1] # removing the default exp\n",
    "        self.unique_dates=list(set([i[1] for i in self.exp_ids]))\n",
    "        self.dates_to_exps={d:[] for d in self.unique_dates}\n",
    "        for d in self.dates_to_exps:\n",
    "            for i in self.exp_ids:\n",
    "                if d in i:\n",
    "                    self.dates_to_exps[d].append(i[0])\n",
    "        self.experiment_ids=[ e for es in self.dates_to_exps.values() for e in es]\n",
    "\n",
    "    def generate_exps_to_runs_mappings(self):\n",
    "        self.exps_to_runs={y:[x.split('/')[-1] for x in glob(f\"mlruns/{y}/*\") if 'meta' not in x] for y in self.experiment_ids}\n",
    "    \n",
    "    def get_exp_and_run_losses_for_date_detailed(self,date:str):\n",
    "\n",
    "        exps=self.dates_to_exps[date]\n",
    "\n",
    "        losses_on_date={}\n",
    "        for exp in exps:\n",
    "            \n",
    "            losses_on_date[exp]={}\n",
    "            runs=self.exps_to_runs[exp]\n",
    "            for run in runs:\n",
    "                run_losses=self.get_run_losses_detailed(exp,run)\n",
    "                losses_on_date[exp][run]={}\n",
    "                losses_on_date[exp][run]=run_losses\n",
    "\n",
    "        return losses_on_date\n",
    "    \n",
    "    def get_exp_and_run_losses_for_date_table(self,date:str):\n",
    "\n",
    "        exps=self.dates_to_exps[date]\n",
    "\n",
    "        losses_on_date={}\n",
    "        for exp in exps:\n",
    "            \n",
    "            losses_on_date[exp]={}\n",
    "            runs=self.exps_to_runs[exp]\n",
    "            for run in runs:\n",
    "                run_losses=self.get_run_losses_table(exp,run)\n",
    "                losses_on_date[exp][run]={}\n",
    "                losses_on_date[exp][run]=run_losses\n",
    "\n",
    "        return losses_on_date\n",
    "\n",
    "    def get_run_losses_detailed(self,exp_id,run_id):\n",
    "        x=[]\n",
    "        with open(f'mlruns/{exp_id}/{run_id}/metrics/train_loss') as f:\n",
    "            x=f.read()\n",
    "            train_losses={y[2]:y[1] for y in [y.split(' ') for y in x.split('\\n')][:-1]}\n",
    "        with open(f'mlruns/{exp_id}/{run_id}/metrics/val_loss') as f:\n",
    "            x=f.read()\n",
    "            val_losses={y[2]:y[1] for y in [y.split(' ') for y in x.split('\\n')][:-1]}\n",
    "        epochs=list(train_losses.keys())\n",
    "        losses={}\n",
    "        for e in epochs:\n",
    "            losses[e]=[train_losses[e],val_losses[e]]\n",
    "        return losses\n",
    "    \n",
    "    def get_run_losses_table(self,exp_id,run_id):\n",
    "        x=[]\n",
    "        with open(f'mlruns/{exp_id}/{run_id}/artifacts/comparison_table.json','r') as f:\n",
    "            json_file=json.load(f)\n",
    "            return [json_file[\"data\"][0][2],json_file[\"data\"][0][3]]\n",
    "    \n",
    "    def compare_losses(self,date,runs):\n",
    "        losses_table=self.get_exp_and_run_losses_for_date_table(date)\n",
    "        run_losses=dict(x for row in losses_table.values() for x in row.items())\n",
    "        return {r:run_losses[r] for r in runs}\n",
    "\n",
    "    def get_run_ids(self,exps):\n",
    "\n",
    "        runs=[]\n",
    "        for e in exps:\n",
    "            runs.extend(self.exps_to_runs[e])\n",
    "        return runs\n",
    "    \n",
    "    def get_exp_names(self,exp_ids):\n",
    "\n",
    "        names=[]\n",
    "        for exp_id in exp_ids:\n",
    "            names.append(self.client.get_experiment(exp_id).name)\n",
    "        return names\n",
    "    \n",
    "    def experiment_names_to_ids(self, names):\n",
    "\n",
    "        exp_ids=[]\n",
    "        for name in names:\n",
    "            exp_ids.append(self.client.get_experiment_by_name(name).experiment_id)\n",
    "        return exp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=get_past_experiments_details()\n",
    "e.dates_to_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.exps_to_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_table=e.get_exp_and_run_losses_for_date_table('2024-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=e.get_exp_and_run_losses_for_date_detailed('2024-01-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.compare_losses('2024-01-22',['a0da97aacfa04a329147b9294e047c6e',\n",
    "  'b966edaecd2e40d4b36f3f1c72d48276'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['a0da97aacfa04a329147b9294e047c6e','b966edaecd2e40d4b36f3f1c72d48276']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(datetime.datetime.fromtimestamp(client.get_run(runs[0]).info.end_time/1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(datetime.datetime.fromtimestamp(model.latest_versions[0].last_updated_timestamp/1e3)).split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/22 16:54:17 INFO mlflow.projects.backend.local: === Asynchronously launching MLflow run with ID eabc0694a9d0456cbbc1cb69d3606c5e ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.projects.submitted_run.LocalSubmittedRun at 0x161d54be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlflow_k8s/lib/python3.8/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2024/01/22 16:54:19 INFO mlflow.projects.utils: === Created directory /var/folders/k5/l531tc5j2070y5w0jlhbhfcw0000gn/T/tmpqtw7wdrw for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2024/01/22 16:54:19 INFO mlflow.projects.backend.local: === Running command 'python src/train.py as 1 1' in run with ID 'eabc0694a9d0456cbbc1cb69d3606c5e' === \n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024/01/22 16:54:24 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/homebrew/Caskroom/miniforge/base/envs/mlflow_k8s/lib/python3.8/site-packages/mlflow/pytorch/_lightning_autolog.py:356: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.4.9 and 2.1.2 and may not succeed with packages outside this range.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/X.csv\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | layers | Sequential | 295   \n",
      "--------------------------------------\n",
      "295       Trainable params\n",
      "0         Non-trainable params\n",
      "295       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlflow_k8s/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anupam/Documents/Codebase/Studies/mlFlow-k8s-Fargate/src/neural_network.py:51: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = self.loss(preds, y)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlflow_k8s/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [00:16<00:00,  1.18it/s]                   \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 48.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 2/3 [00:00<00:00, 76.22it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 44.73it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 20/20 [00:36<00:00,  0.54it/s]              \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anupam/Documents/Codebase/Studies/mlFlow-k8s-Fargate/src/neural_network.py:51: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = self.loss(preds, y)\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "2024/01/22 16:55:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/homebrew/Caskroom/miniforge/base/envs/mlflow_k8s/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " tensor(15199.9512) \n",
      "\n",
      "\n",
      "{'date': '2024-01-22', 'runID': ['2ad12d336b044bfa980b73e2dcd14f39'], 'train_loss': array(15199.951, dtype=float32), 'val_loss': array(9460.56, dtype=float32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/22 16:55:24 INFO mlflow.projects: === Run (ID 'eabc0694a9d0456cbbc1cb69d3606c5e') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "mlflow.projects.run(\n",
    "uri=\".\",\n",
    "run_name=\"nn\",\n",
    "entry_point=\"train\",\n",
    "backend='local',\n",
    "synchronous=False,\n",
    "env_manager='local',\n",
    "parameters={\n",
    "    'name':\"as\",\n",
    "    'epochs':1,\n",
    "    'trials':1\n",
    "},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-22 16:54:24.071000\n",
      "2024-01-22 11:39:33.706000\n",
      "2024-01-22 11:39:24.952000\n",
      "2024-01-22 11:39:03.457000\n",
      "2024-01-18 19:39:28.311000\n",
      "2024-01-18 19:32:44.936000\n",
      "2024-01-18 14:00:21.548000\n"
     ]
    }
   ],
   "source": [
    "for x in client.search_experiments():\n",
    "    print(datetime.datetime.fromtimestamp(x.creation_time/1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///Users/anupam/Documents/Codebase/Studies/mlFlow-k8s-Fargate/mlruns/210312274051288785', creation_time=1705922664071, experiment_id='210312274051288785', last_update_time=1705922664071, lifecycle_stage='active', name='as', tags={}>,\n",
       " <Experiment: artifact_location='file:///mlflow/tmp/mlruns/147575009518632148', creation_time=1705903773706, experiment_id='147575009518632148', last_update_time=1705903773706, lifecycle_stage='active', name='qwdawd', tags={}>,\n",
       " <Experiment: artifact_location='file:///mlflow/tmp/mlruns/432371529360376795', creation_time=1705903764952, experiment_id='432371529360376795', last_update_time=1705903764952, lifecycle_stage='active', name='sd', tags={}>,\n",
       " <Experiment: artifact_location='file:///mlflow/tmp/mlruns/153729051477138785', creation_time=1705903743457, experiment_id='153729051477138785', last_update_time=1705903743457, lifecycle_stage='active', name='sdf', tags={}>,\n",
       " <Experiment: artifact_location='file:///mlflow/tmp/mlruns/737505758160016794', creation_time=1705586968311, experiment_id='737505758160016794', last_update_time=1705586968311, lifecycle_stage='active', name='HP-Optuna', tags={}>,\n",
       " <Experiment: artifact_location='file:///Users/anupam/Documents/Codebase/Studies/mlFlow-k8s-Fargate/mlruns/765617377597547522', creation_time=1705586564936, experiment_id='765617377597547522', last_update_time=1705586564936, lifecycle_stage='active', name='local-opt', tags={}>,\n",
       " <Experiment: artifact_location='file:///Users/anupam/Documents/Codebase/Studies/mlFlow-k8s-Fargate/mlruns/0', creation_time=1705566621548, experiment_id='0', last_update_time=1705566621548, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AK=os.environ[\"AK\"]\n",
    "SK=os.environ[\"SK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching \"data/X.csv\" in \"mlops-optuna\"\n",
      "Searching \"data/y.csv\" in \"mlops-optuna\"\n"
     ]
    }
   ],
   "source": [
    "from utils.upload_to_s3 import upload_recursively_to_s3\n",
    "upload_recursively_to_s3(\"data\",AK,SK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "local path data/X.csv\n",
      "relative path X.csv\n",
      "s3 path data/X.csv\n",
      "\n",
      "\n",
      "\n",
      "local path data/y.csv\n",
      "relative path y.csv\n",
      "s3 path data/y.csv\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(\"data\"):\n",
    "\n",
    "    for filename in files:\n",
    "            \n",
    "        print(\"\\n\\n\")\n",
    "        # construct the full local path\n",
    "        local_path = os.path.join(root, filename)\n",
    "        print(\"local path\",local_path)\n",
    "        # construct the full Dropbox path\n",
    "        relative_path = os.path.relpath(local_path, \"data\")\n",
    "        print(\"relative path\",relative_path)\n",
    "        s3_path = os.path.join(\"data\", relative_path)\n",
    "        print(\"s3 path\",s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "m=mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=m.get_experiment_by_name(name=\"s3_trial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "(datetime.now()- datetime.fromtimestamp(exp.last_update_time/1e3)).seconds/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "c=mlflow.MlflowClient()\n",
    "\n",
    "run=c.get_run('1e6e3e0d804245b4b17d833b267f8cba').info.run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analyze_runs import MLFlow_app_client\n",
    "\n",
    "e=MLFlow_app_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['422451744140292354']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.experiment_names_to_ids(['s3_trial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ['730a35a1394b4e77910db4ce65e876e1', '1e6e3e0d804245b4b17d833b267f8cba', '6c92da5031454a0f8a4a56e8e8a845cf', '0860bfa405ed47fd8632043bb0233cd0', '9f4068fd078d4f8992a1621a69f5fd4b', 'ef2389883a754f21b7e3ff89efd90fce'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_runs,run_names=e.get_run_names_in_exp(['422451744140292354'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['730a35a1394b4e77910db4ce65e876e1',\n",
       " '1e6e3e0d804245b4b17d833b267f8cba',\n",
       " '6c92da5031454a0f8a4a56e8e8a845cf',\n",
       " '0860bfa405ed47fd8632043bb0233cd0',\n",
       " '9f4068fd078d4f8992a1621a69f5fd4b',\n",
       " 'ef2389883a754f21b7e3ff89efd90fce']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['version_0.31_0.08_6_107',\n",
       " 'version_0.36_0.09_51_21_71_10_17',\n",
       " 'version_0.56_0.06_6_9_19_5_28',\n",
       " 'version_0.49_0.03_85_11_11_17_34',\n",
       " 'version_0.6_0.08_25_4_55_62',\n",
       " 'version_0.57_0.07_9_28_32_16']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_selected=['version_0.36_0.09_51_21_71_10_17','version_0.56_0.06_6_9_19_5_28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_run_ids=[]\n",
    "for name,run_id in zip(run_names,filtered_runs):\n",
    "    if name in runs_selected:\n",
    "        selected_run_ids.append(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1e6e3e0d804245b4b17d833b267f8cba', '6c92da5031454a0f8a4a56e8e8a845cf']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_table=e.compare_losses('2024-01-25',selected_run_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1e6e3e0d804245b4b17d833b267f8cba': [15219.341796875, 9746.0107421875],\n",
       " '6c92da5031454a0f8a4a56e8e8a845cf': [15195.724609375, 9489.216796875]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open(\"../k8s-deployment.yaml\",\"r\") as f:\n",
    "    k8s_yaml=f.read()\n",
    "\n",
    "image_version=re.findall('mlops-webapp:v\\d+\\.\\d+\\.\\d+',k8s_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_k8s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
